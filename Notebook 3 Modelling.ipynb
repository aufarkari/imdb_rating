{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34baa1ac",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Importing-Library\" data-toc-modified-id=\"Importing-Library-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Importing Library</a></span></li><li><span><a href=\"#Reading-Data\" data-toc-modified-id=\"Reading-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reading Data</a></span></li><li><span><a href=\"#Data-Pre-Processing\" data-toc-modified-id=\"Data-Pre-Processing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Pre Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Feature-Selection\" data-toc-modified-id=\"Feature-Selection-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Feature Selection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Filtering-Sparse-Columns\" data-toc-modified-id=\"Filtering-Sparse-Columns-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Filtering Sparse Columns</a></span></li><li><span><a href=\"#Filtering-Columns-with-No-Variance\" data-toc-modified-id=\"Filtering-Columns-with-No-Variance-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Filtering Columns with No Variance</a></span></li><li><span><a href=\"#Filtering-Highly-Correlated-Columns\" data-toc-modified-id=\"Filtering-Highly-Correlated-Columns-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Filtering Highly Correlated Columns</a></span></li><li><span><a href=\"#Missing-Value-Imputation-with-KNN-Imputer\" data-toc-modified-id=\"Missing-Value-Imputation-with-KNN-Imputer-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Missing Value Imputation with KNN Imputer</a></span></li><li><span><a href=\"#Recursive-Feature-Elimination-with-CV-to-Determine-the-Number-of-Features\" data-toc-modified-id=\"Recursive-Feature-Elimination-with-CV-to-Determine-the-Number-of-Features-3.1.5\"><span class=\"toc-item-num\">3.1.5&nbsp;&nbsp;</span>Recursive Feature Elimination with CV to Determine the Number of Features</a></span></li><li><span><a href=\"#Recursive-Feature-Elimination-to-Select-the-Numerical-Features\" data-toc-modified-id=\"Recursive-Feature-Elimination-to-Select-the-Numerical-Features-3.1.6\"><span class=\"toc-item-num\">3.1.6&nbsp;&nbsp;</span>Recursive Feature Elimination to Select the Numerical Features</a></span></li></ul></li><li><span><a href=\"#Tokenizing-sparse-text-feature\" data-toc-modified-id=\"Tokenizing-sparse-text-feature-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Tokenizing sparse text feature</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tokenizing-director_writer\" data-toc-modified-id=\"Tokenizing-director_writer-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Tokenizing director_writer</a></span></li><li><span><a href=\"#Tokenizing-Parent-Title\" data-toc-modified-id=\"Tokenizing-Parent-Title-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Tokenizing Parent Title</a></span></li></ul></li></ul></li><li><span><a href=\"#ML-Pipeline\" data-toc-modified-id=\"ML-Pipeline-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>ML Pipeline</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-1:-Baseline-Naive-Prediction\" data-toc-modified-id=\"Model-1:-Baseline-Naive-Prediction-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Model 1: Baseline Naive Prediction</a></span></li><li><span><a href=\"#Model-2:-Linear-Model-Pipeline\" data-toc-modified-id=\"Model-2:-Linear-Model-Pipeline-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Model 2: Linear Model Pipeline</a></span></li><li><span><a href=\"#Model-3:-XBG-Pipeline\" data-toc-modified-id=\"Model-3:-XBG-Pipeline-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Model 3: XBG Pipeline</a></span></li><li><span><a href=\"#Model-4:-XBG-Pipeline-with-Sparse-Text-Data-Tokenization\" data-toc-modified-id=\"Model-4:-XBG-Pipeline-with-Sparse-Text-Data-Tokenization-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Model 4: XBG Pipeline with Sparse Text Data Tokenization</a></span></li></ul></li><li><span><a href=\"#Model-Inspection\" data-toc-modified-id=\"Model-Inspection-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Inspection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Variance-Explained-of-the-Tokenizers\" data-toc-modified-id=\"Variance-Explained-of-the-Tokenizers-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Variance Explained of the Tokenizers</a></span></li><li><span><a href=\"#Feature-Importance\" data-toc-modified-id=\"Feature-Importance-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Feature Importance</a></span></li><li><span><a href=\"#Permutation-Importance\" data-toc-modified-id=\"Permutation-Importance-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Permutation Importance</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de11dfe2",
   "metadata": {},
   "source": [
    "# Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107d4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV,cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import KNNImputer,SimpleImputer,IterativeImputer\n",
    "from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ff98f",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7ff221",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/karteuku/Desktop/IMDB_rating/imdb_rating/data/data.csv')\n",
    "\n",
    "data.set_index('tconst',inplace= True)\n",
    "\n",
    "cols_drop = ['primaryTitle', 'originalTitle','isAdult','directors','writers']\n",
    "data = data.drop(columns = cols_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9238a7d3",
   "metadata": {},
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9926c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['averageRating'])\n",
    "y = data['averageRating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a622d1be",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35277616",
   "metadata": {},
   "source": [
    "### Filtering Sparse Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1d7ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sparse_feature(data, sparsity_threshold):\n",
    "    '''\n",
    "    This function filter columns with missing value fraction larger than the sparsity_threshold\n",
    "    '''\n",
    "    number_nan = pd.DataFrame(data.isna().sum(axis= 0)/len(data))\n",
    "    number_nan.columns = ['number_nan']\n",
    "    sparse_columns = number_nan[number_nan['number_nan']>=sparsity_threshold].index\n",
    "    print(\"Sparse columns : \" + str(sparse_columns))\n",
    "    \n",
    "    non_sparse_columns = number_nan[number_nan['number_nan']<sparsity_threshold].index\n",
    "    \n",
    "    data = data[non_sparse_columns]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6844a728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse columns : Index(['endYear', 'max_episodeNumber', 'max_seasonNumber'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_train = filter_sparse_feature(X_train, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d8be7a",
   "metadata": {},
   "source": [
    "### Filtering Columns with No Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abdb9d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_no_variance_feature(data):\n",
    "    '''\n",
    "    This function filter columns with zero variance\n",
    "    '''\n",
    "    no_variance_feature_list = []\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if data[col].dtypes !='object':\n",
    "            if data[col].var()==0: \n",
    "                no_variance_feature_list.append(col)\n",
    "    \n",
    "    print(\"Columns with no variance : \" + str(no_variance_feature_list))\n",
    "            \n",
    "    data = data.drop(columns = no_variance_feature_list)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d212a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with no variance : []\n"
     ]
    }
   ],
   "source": [
    "X_train = filter_no_variance_feature(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2875633",
   "metadata": {},
   "source": [
    "### Filtering Highly Correlated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f27394",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating list to store numerical column and non-numerical column \n",
    "object_col_list = []\n",
    "num_col_list = []\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtypes =='object':\n",
    "        object_col_list.append(col)\n",
    "    else :\n",
    "        num_col_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2e441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_feature(data, correlation_threshold):\n",
    "    '''\n",
    "    This function remove columns with correlation higher than correlation_threshold\n",
    "    '''\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = data[num_col_list].corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find features with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > correlation_threshold)]\n",
    "    print(\"Highly correlated features : \" + str(to_drop))\n",
    "\n",
    "    # Drop features \n",
    "    data.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "009e8468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly correlated features : ['unique_region', 'unique_title']\n"
     ]
    }
   ],
   "source": [
    "X_train = remove_highly_correlated_feature(X_train, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f10d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Updating object_col_list and num_col_list\n",
    "object_col_list = []\n",
    "num_col_list = []\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtypes =='object':\n",
    "        object_col_list.append(col)\n",
    "    else :\n",
    "        num_col_list.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862dc91",
   "metadata": {},
   "source": [
    "### Missing Value Imputation with KNN Imputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b290d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating feature_list, which contains all the numerical columns and 2 columnns containing sparse text features :\n",
    "## directors_writers and parentTconst\n",
    "feature_list = num_col_list.copy()\n",
    "feature_list.append('directors_writers')\n",
    "feature_list.append('parentTconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a12f248e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting started...\n",
      "Fitting took 1116.806s.\n"
     ]
    }
   ],
   "source": [
    "## Using KNN imputation \n",
    "knn_imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "t0 = time.time()\n",
    "print(\"Fitting started...\")\n",
    "X_train_imputed = knn_imputer.fit_transform(X_train[num_col_list])\n",
    "print(f\"Fitting took {time.time() - t0:0.3f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a25278bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Turning the X_train_imputed into a DataFrame object\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, \n",
    "                               columns = num_col_list,\n",
    "                               index = list(X_train.index)\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd901088",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing the X_test data using the fitted knn-imputer\n",
    "X_test_imputed = knn_imputer.transform(X_test[num_col_list])\n",
    "\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, \n",
    "                              columns = num_col_list,\n",
    "                              index = list(X_test.index)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ca0035",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination with CV to Determine the Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94c6e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specifying the rfe_base_pipeline to optimize the base_model used for RFECV procedure\n",
    "\n",
    "rfe_base_model = xgb.XGBRegressor()\n",
    "\n",
    "rfe_base_pipeline = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()),  \n",
    "    ('model', rfe_base_model)\n",
    "])\n",
    "\n",
    "rfe_base_param_grid = {\n",
    "    'model__max_depth': [2, 3, 5, 7, 10],\n",
    "    'model__n_estimators': [10, 100, 500],\n",
    "    'model__min_child_weight': [1, 5, 10],\n",
    "    'model__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'model__subsample': [0.6, 0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eb83cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting started...\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting took 731.704s.\n"
     ]
    }
   ],
   "source": [
    "## Performing randomized search to optimize the rfe_base model\n",
    "rfe_base_search = RandomizedSearchCV(rfe_base_pipeline, param_distributions=rfe_base_param_grid, verbose=1, \n",
    "                                      n_iter=3, n_jobs = -1, cv = 3)\n",
    "t0 = time.time()\n",
    "print(\"Fitting started...\")\n",
    "rfe_base_search.fit(X_train_imputed, y_train)\n",
    "print(f\"Fitting took {time.time() - t0:0.3f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b941e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
       "             colsample_bynode=None, colsample_bytree=0.6, gamma=0.5,\n",
       "             gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=None, max_delta_step=None, max_depth=7,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "             scale_pos_weight=None, subsample=1.0, tree_method=None,\n",
       "             validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get best parameters and score\n",
    "best_params = rfe_base_search.best_params_\n",
    "        \n",
    "## Update rfe_base parameters\n",
    "tuned_params = {item[7:]: best_params[item] for item in best_params}\n",
    "rfe_base_model.set_params(**tuned_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e125b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Pipeline object to perform RFECV procedure \n",
    "class PipelineRFE(Pipeline):\n",
    "    '''\n",
    "    This is a Pipeline object to perform RFE procedure on sklearn Pipeline.\n",
    "    Source: https://towardsdatascience.com/model-design-and-selection-with-scikit-learn-18a29041d02a\n",
    "    '''\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        super(PipelineRFE, self).fit(X, y, **fit_params)\n",
    "        self.feature_importances_ = self.steps[-1][-1].feature_importances_\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4a81740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting started...\n",
      "Fitting took 72.250s.\n"
     ]
    }
   ],
   "source": [
    "## Defining the Pipeline for RFECV procedure\n",
    "rfecv_pipeline = PipelineRFE([\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('model', rfe_base_model)\n",
    "])\n",
    "\n",
    "## Initialize RFECV object\n",
    "rfecv_min_features_to_select = 10\n",
    "rfecv_step = 5\n",
    "feature_selector_rfecv = RFECV(rfecv_pipeline, cv = 3, verbose = 0, \n",
    "                               min_features_to_select = rfecv_min_features_to_select, \n",
    "                               step = rfecv_step)\n",
    "\n",
    "## Fit RFECV\n",
    "t0 = time.time()\n",
    "print(\"Fitting started...\")\n",
    "feature_selector_rfecv.fit(X_train_imputed, y_train)\n",
    "print(f\"Fitting took {time.time() - t0:0.3f}s.\")\n",
    "\n",
    "## Get selected features\n",
    "feature_names_rfecv = X_train_imputed.columns\n",
    "selected_features_rfecv = feature_names_rfecv[feature_selector_rfecv.support_].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88a112e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of RFECV selected features is 60\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of RFECV selected features is \" + str(len(selected_features_rfecv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd4c5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing the RFECV performance into a DataFrame\n",
    "performance_curve = {\"Number of Features\": list(range(rfecv_min_features_to_select, \n",
    "                                                      len(feature_names_rfecv) + 1,\n",
    "                                                      rfecv_step\n",
    "                                                     )\n",
    "                                               ),\n",
    "                    \"Score\": feature_selector_rfecv.grid_scores_}\n",
    "performance_curve = pd.DataFrame(performance_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "689fd489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'RFECV Performance Curve')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plotting the performance to gauge the number of feature to be selected \n",
    "sns.lineplot(x = \"Number of Features\", y = \"Score\", data = performance_curve)\n",
    "plt.title(\"RFECV Performance Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766e7e0",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination to Select the Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "feb1a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting started...\n",
      "Fitting took 161.344s.\n"
     ]
    }
   ],
   "source": [
    "## Defining the Pipeline object to perform RFE\n",
    "rfe_pipeline = PipelineRFE([\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('model', rfe_base_model)\n",
    "])\n",
    "\n",
    "## Initialize RFE object\n",
    "n_features_to_select = 33 ## Based on the result of RFECV\n",
    "feature_selector_rfe = RFE(rfe_pipeline, n_features_to_select = n_features_to_select, step = 4, verbose = 0)\n",
    "\n",
    "## Fit RFE\n",
    "print(\"Fitting started...\")\n",
    "feature_selector_rfe.fit(X_train_imputed, y_train)\n",
    "print(f\"Fitting took {time.time() - t0:0.3f}s.\")\n",
    "\n",
    "## Get selected features labels\n",
    "feature_names_rfe = X_train_imputed.columns\n",
    "selected_features_rfe = feature_names_rfe[feature_selector_rfe.support_].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16d1e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing the selected numerical features and the 2 sparse text features on selected_features list\n",
    "selected_features = selected_features_rfe.copy()\n",
    "selected_features.append('directors_writers')\n",
    "selected_features.append('parentTconst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e99418f",
   "metadata": {},
   "source": [
    "## Tokenizing sparse text feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92619a75",
   "metadata": {},
   "source": [
    "### Tokenizing director_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d949b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectorWriterSparseTokenizer(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    This is a custom Transformer object to perform 2 transformation on a sparse text columns : \n",
    "    1. CountVectorizer and 2. TruncatedSVD.\n",
    "    \n",
    "    It differs from the off-the-shelves sklearn object by enabling treatment of missing value.\n",
    "    \n",
    "    This Transformer is specific for 'directors_writers' column\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        This function initializes the DirectorWriterSparseTokenizer Transformer object \n",
    "        '''\n",
    "        super().__init__()\n",
    "        ## Storing the index of the non missing value data on the original DataFrame\n",
    "        self.index_ = None\n",
    "        \n",
    "        ## Storing the column which contains the sparse text data to be transformed\n",
    "        self.column_ = 'directors_writers'\n",
    "        \n",
    "        ## The CountVectorizer object to vectorize the text data\n",
    "        self.tokenizer_ = None\n",
    "        \n",
    "        ## The sparse matrix object storing the tokenized data\n",
    "        self.tokenized_matrix_ = None\n",
    "        \n",
    "        ## The TruncatedSVD object to reduce the dimensionality\n",
    "        self.tsvd_ = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        '''\n",
    "        This functions fit the DirectorWriterSparseTokenizer Transformer object with the training data\n",
    "        and return a fitted Tranformer object\n",
    "        '''\n",
    "        self.index_ = X[self.column_].dropna().index\n",
    "        \n",
    "        ## First transformation : fitting the CountVectorizer\n",
    "        self.tokenizer_ = CountVectorizer(tokenizer=lambda x: x.split(', '), binary=True\n",
    "                                         )\n",
    "        self.tokenizer_ = self.tokenizer_.fit(X[self.column_].dropna())\n",
    "        \n",
    "        ## Storing the full tokenized data into a scipy sparse matrix object\n",
    "        self.tokenized_matrix_ = csr_matrix(self.tokenizer_.transform(X[self.column_].dropna()))\n",
    "        \n",
    "        ## Second transformation : fitting the TruncatedSVD\n",
    "        self.tsvd_ = TruncatedSVD(n_components=75, n_iter=5, random_state=42)\n",
    "        self.tsvd_ = self.tsvd_.fit(self.tokenized_matrix_)\n",
    "        \n",
    "        ## Return the fitted Transformer object from the 2 Transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        '''\n",
    "        This function does the following: \n",
    "        1. It takes the self.column_ from X DataFrame and drop missing values.\n",
    "        2. It performs the DirectorWriterSparseTokenizer transformation on the array from step 1.\n",
    "        3. It joins the result of the DirectorWriterSparseTokenizer transformation into the original X DataFrame \n",
    "           and drop the self.column_ so that the DataFrame can be used for the next step in the Pipeline\n",
    "        \n",
    "        '''\n",
    "        ## Storing the index of the data so that it can be used to rejoined the transformed data\n",
    "        X_index_ = X[self.column_].dropna().index\n",
    "        \n",
    "        ## Performing the transformation on the data\n",
    "        X_tsvd_tokenized_matrix_ = self.tsvd_.transform(csr_matrix(self.tokenizer_.transform(X[self.column_].dropna())))\n",
    "        \n",
    "        ## Converting the X_tsvd_tokenized_matrix_ object in a DataFrame with the appropriate index\n",
    "        X_tsvd_tokenized_matrix_df = pd.DataFrame(X_tsvd_tokenized_matrix_, \n",
    "                                                  index = X_index_, \n",
    "                                                  columns = [self.column_ + 'tsvd_' + str(col) \n",
    "                                                             for col in range(X_tsvd_tokenized_matrix_.shape[1])]\n",
    "                                                 )\n",
    "        \n",
    "        ## Joining the X_tsvd_tokenized_matrix_df into the initial DataFrame \n",
    "        X_output = X.join(X_tsvd_tokenized_matrix_df)\n",
    "        \n",
    "        ## Dropping the self.column_ from X_output \n",
    "        X_output = X_output.drop(columns = [self.column_])\n",
    "\n",
    "        return X_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6bb90f",
   "metadata": {},
   "source": [
    "### Tokenizing Parent Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb0b8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParentTitleSparseTokenizer(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    This is a custom Transformer object to perform 2 transformation on a sparse text columns : \n",
    "    1. CountVectorizer and 2. TruncatedSVD.\n",
    "    \n",
    "    It differs from the off-the-shelves sklearn object by enabling treatment of missing value.\n",
    "    \n",
    "    This Transformer is specific for 'parentTconst' column\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        This function initializes the ParentTitleSparseTokenizer Transformer object \n",
    "        '''\n",
    "        super().__init__()\n",
    "        ## Storing the index of the non missing value data on the original DataFrame\n",
    "        self.index_ = None\n",
    "        \n",
    "        ## Storing the column which contains the sparse text data to be transformed\n",
    "        self.column_ = 'parentTconst'\n",
    "        \n",
    "        ## The CountVectorizer object to vectorize the text data\n",
    "        self.tokenizer_ = None\n",
    "        \n",
    "        ## The sparse matrix object storing the tokenized data\n",
    "        self.tokenized_matrix_ = None\n",
    "        self.tsvd_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        '''\n",
    "        This functions fit the ParentTitleSparseTokenizer Transformer object with the training data\n",
    "        and return a fitted Tranformer object\n",
    "        '''\n",
    "        self.index_ = X[self.column_].dropna().index\n",
    "        \n",
    "        ## First transformation : fitting the CountVectorizer\n",
    "        self.tokenizer_ = CountVectorizer(tokenizer=lambda x: x.split(', '), binary=True\n",
    "                                         )\n",
    "        self.tokenizer_ = self.tokenizer_.fit(X[self.column_].dropna())\n",
    "        \n",
    "        ## Storing the full tokenized data into a scipy sparse matrix object\n",
    "        self.tokenized_matrix_ = csr_matrix(self.tokenizer_.transform(X[self.column_].dropna()))\n",
    "        \n",
    "        ## Second transformation : fitting the TruncatedSVD\n",
    "        self.tsvd_ = TruncatedSVD(n_components=125, n_iter=5, random_state=42)\n",
    "        self.tsvd_ = self.tsvd_.fit(self.tokenized_matrix_)\n",
    "        \n",
    "        ## Return the fitted Transformer object from the 2 Transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        '''\n",
    "        This function does the following: \n",
    "        1. It takes the self.column_ from X DataFrame and drop missing values.\n",
    "        2. It performs the DirectorWriterSparseTokenizer transformation on the array from step 1.\n",
    "        3. It joins the result of the ParentTitleSparseTokenizer transformation into the original X DataFrame \n",
    "           and drop the self.column_ so that the DataFrame can be used for the next step in the Pipeline\n",
    "        \n",
    "        '''\n",
    "        ## Storing the index of the data so that it can be used to rejoined the transformed data\n",
    "        X_index_ = X[self.column_].dropna().index\n",
    "        \n",
    "        ## Performing the transformation on the data\n",
    "        X_tsvd_tokenized_matrix_ = self.tsvd_.transform(csr_matrix(self.tokenizer_.transform(X[self.column_].dropna())))\n",
    "        \n",
    "        ## Converting the X_tsvd_tokenized_matrix_ object in a DataFrame with the appropriate index\n",
    "        X_tsvd_tokenized_matrix_df = pd.DataFrame(X_tsvd_tokenized_matrix_, \n",
    "                                                  index = X_index_, \n",
    "                                                  columns = [self.column_ + 'tsvd_' + str(col) \n",
    "                                                             for col in range(X_tsvd_tokenized_matrix_.shape[1])]\n",
    "                                                 )\n",
    "        \n",
    "        ## Joining the X_tsvd_tokenized_matrix_df into the initial DataFrame \n",
    "        X_output = X.join(X_tsvd_tokenized_matrix_df)\n",
    "        \n",
    "        ## Dropping the self.column_ from X_output\n",
    "        X_output = X_output.drop(columns = [self.column_])\n",
    "\n",
    "        return X_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12dec2",
   "metadata": {},
   "source": [
    "# ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec23d5d0",
   "metadata": {},
   "source": [
    "## Model 1: Baseline Naive Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "174fc3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Naive Model Mean Absolute Error is 1.074\n"
     ]
    }
   ],
   "source": [
    "naive_mae = mean_absolute_error(y_test, [y_train.mean()]*len(y_test))\n",
    "\n",
    "print(f\"The Naive Model Mean Absolute Error is {naive_mae:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7eeb37f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Naive Model Mean Squared Error is 1.933\n"
     ]
    }
   ],
   "source": [
    "naive_mse = mean_squared_error(y_test, [y_train.mean()]*len(y_test))\n",
    "\n",
    "print(f\"The Naive Model Mean Squared Error is {naive_mse:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbdd6399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Naive Model R2 Score is -0.000\n"
     ]
    }
   ],
   "source": [
    "naive_r2_score = r2_score(y_test, [y_train.mean()]*len(y_test))\n",
    "\n",
    "print(f\"The Naive Model R2 Score is {naive_r2_score:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d52214",
   "metadata": {},
   "source": [
    "## Model 2: Linear Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae2e4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the elastic net pipeline and parameters\n",
    "el_net_pipeline = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()), \n",
    "    ('model', ElasticNet())\n",
    "])\n",
    "\n",
    "el_net_param_grid = {\n",
    "    'model__alpha' : [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0],\n",
    "    'model__l1_ratio' : np.arange(0, 1, 0.01)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93c772de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting started...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Fitting took 6.946s.\n"
     ]
    }
   ],
   "source": [
    "## Tuning the Linear Model with RandomizedSearchCV\n",
    "t0 = time.time()\n",
    "el_net_search = RandomizedSearchCV(el_net_pipeline, param_distributions=el_net_param_grid, verbose=1,\n",
    "                                   n_iter=4, n_jobs = -1, cv = 3,scoring='r2'\n",
    "                                  )\n",
    "print(\"Fitting started...\")\n",
    "el_net_search.fit(X_train_imputed[selected_features_rfe], y_train)\n",
    "print(f\"Fitting took {time.time() - t0:0.3f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bc4ee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear Model CV Best R2 Score is 0.223\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Linear Model CV Best R2 Score is {el_net_search.best_score_:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcb46de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear Model Mean Absolute Error is 0.917\n"
     ]
    }
   ],
   "source": [
    "el_net_mae = mean_absolute_error(y_test, \n",
    "                                 el_net_search.predict(X_test_imputed[selected_features_rfe])\n",
    "                                )\n",
    "\n",
    "print(f\"The Linear Model Mean Absolute Error is {el_net_mae:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d9013f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear Model Mean Absolute Error is 1.512\n"
     ]
    }
   ],
   "source": [
    "el_net_mse = mean_squared_error(y_test, \n",
    "                                 el_net_search.predict(X_test_imputed[selected_features_rfe])\n",
    "                                )\n",
    "\n",
    "print(f\"The Linear Model Mean Absolute Error is {el_net_mse:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18e56a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear Model R2 Score is 0.218\n"
     ]
    }
   ],
   "source": [
    "el_net_r2_score = r2_score(y_test, \n",
    "                           el_net_search.predict(X_test_imputed[selected_features_rfe])\n",
    "                          )\n",
    "\n",
    "print(f\"The Linear Model R2 Score is {el_net_r2_score :0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b691a8",
   "metadata": {},
   "source": [
    "## Model 3: XBG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "caeb893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the pipeline and the parameter tuning for XGB pipepline\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()),  \n",
    "    ('model', xgb.XGBRegressor())\n",
    "])\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'model__max_depth': [2, 3, 5, 7, 10],\n",
    "    'model__n_estimators': [10, 100, 500],\n",
    "    'model__min_child_weight': [1, 5, 10],\n",
    "    'model__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'model__subsample': [0.6, 0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24b42bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting started...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Fitting took 628.812s.\n"
     ]
    }
   ],
   "source": [
    "## Tuning the XGB Model with RandomizedSearchCV\n",
    "t0 = time.time()\n",
    "print(\"Fitting started...\")\n",
    "xgb_search = RandomizedSearchCV(xgb_pipeline, param_distributions=xgb_param_grid, verbose=1, \n",
    "                                n_iter=4, n_jobs = -1, cv = 3,scoring='r2')\n",
    "xgb_search.fit(X_train[selected_features_rfe], \n",
    "               y_train)\n",
    "print(f\"Fitting took {time.time() - t0:0.3f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f460893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The XGB Model CV Best R2 Score is 0.347\n"
     ]
    }
   ],
   "source": [
    "print(f\"The XGB Model CV Best R2 Score is {xgb_search.best_score_:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18244c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The XGB Model Mean Absolute Error is 0.821\n"
     ]
    }
   ],
   "source": [
    "xgb_mae = mean_absolute_error(y_test, \n",
    "                              xgb_search.predict(X_test[selected_features_rfe])\n",
    "                             )\n",
    "\n",
    "print(f\"The XGB Model Mean Absolute Error is {xgb_mae:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb8f089c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The XGB Model Mean Squared Error is 1.271\n"
     ]
    }
   ],
   "source": [
    "xgb_mse = mean_squared_error(y_test, \n",
    "                             xgb_search.predict(X_test[selected_features_rfe])\n",
    "                            )\n",
    "\n",
    "print(f\"The XGB Model Mean Squared Error is {xgb_mse:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5735615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The XGB Model R2 Score is 0.342\n"
     ]
    }
   ],
   "source": [
    "xgb_r2_score = r2_score(y_test, \n",
    "                        xgb_search.predict(X_test[selected_features_rfe])\n",
    "                        )\n",
    "\n",
    "print(f\"The XGB Model R2 Score is {xgb_r2_score:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b906376d",
   "metadata": {},
   "source": [
    "## Model 4: XBG Pipeline with Sparse Text Data Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9a015da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the pipeline and parameter tuning for XGB with Sparse Tokenizer Model\n",
    "xgb_tokenizer_pipeline = Pipeline([\n",
    "    ('parent_title_tokenizer', ParentTitleSparseTokenizer()),\n",
    "    ('director_writer_tokenizer', DirectorWriterSparseTokenizer()),\n",
    "    ('standard_scaler', StandardScaler()),  \n",
    "    ('model', xgb.XGBRegressor())\n",
    "])\n",
    "\n",
    "xgb_tokenizer_param_grid = {\n",
    "    'model__max_depth': [2, 3, 5, 7, 10],\n",
    "    'model__n_estimators': [10, 100, 500],\n",
    "    'model__min_child_weight': [1, 5, 10],\n",
    "    'model__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'model__subsample': [0.6, 0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4f8297c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting started...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting took 1572.745s.\n"
     ]
    }
   ],
   "source": [
    "## Tuning the XGB with Sparse Tokenizer Model with RandomizedSearchCV\n",
    "t0 = time.time()\n",
    "print(\"Fitting started...\")\n",
    "xgb_tokenizer_search = RandomizedSearchCV(xgb_tokenizer_pipeline, \n",
    "                                          param_distributions=xgb_tokenizer_param_grid, verbose=1, \n",
    "                                          n_iter=4, n_jobs = -1, cv = 3,scoring='r2')\n",
    "xgb_tokenizer_search.fit(X_train[selected_features], y_train)\n",
    "print(f\"Fitting took {time.time() - t0:0.3f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9743d379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The XGB with Sparse Tokenizer Model CV Best R2 Score is 0.365\n"
     ]
    }
   ],
   "source": [
    "print(f\"The XGB with Sparse Tokenizer Model CV Best R2 Score is {xgb_tokenizer_search.best_score_:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a901e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The XGB with Sparse Tokenizer Model Mean Absolute Error is 0.792\n"
     ]
    }
   ],
   "source": [
    "xgb_tokenizer_mae = mean_absolute_error(y_test, \n",
    "                                       xgb_tokenizer_search.predict(X_test[selected_features])\n",
    "                                      )\n",
    "\n",
    "print(f\"The XGB with Sparse Tokenizer Model Mean Absolute Error is {xgb_tokenizer_mae:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d737eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The XGB with Sparse Tokenizer Model Mean Squared Error is 1.215\n"
     ]
    }
   ],
   "source": [
    "xgb_tokenizer_mse = mean_squared_error(y_test, \n",
    "                                       xgb_tokenizer_search.predict(X_test[selected_features])\n",
    "                                      )\n",
    "\n",
    "print(f\"The XGB with Sparse Tokenizer Model Mean Squared Error is {xgb_tokenizer_mse:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e17d712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The XGB with Sparse Tokenizer Model R2 Score is 0.371\n"
     ]
    }
   ],
   "source": [
    "xgb_tokenizer_r2_score = r2_score(y_test, \n",
    "                                  xgb_tokenizer_search.predict(X_test[selected_features])\n",
    "                                  )\n",
    "\n",
    "print(f\"The XGB with Sparse Tokenizer Model R2 Score is {xgb_tokenizer_r2_score:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea619459",
   "metadata": {},
   "source": [
    "# Model Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1971953e",
   "metadata": {},
   "source": [
    "## Variance Explained of the Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26833e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ParentTitleSparseTokenizer initial dimension is 32048\n"
     ]
    }
   ],
   "source": [
    "parent_title_num_token = xgb_tokenizer_search.best_estimator_.steps[0][1].tokenized_matrix_.shape[0]\n",
    "\n",
    "print(f\"The ParentTitleSparseTokenizer initial dimension is {parent_title_num_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e333f77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ParentTitleSparseTokenizer Explained Variance is 13.8 %\n"
     ]
    }
   ],
   "source": [
    "parent_title_explained_variance = xgb_tokenizer_search.best_estimator_.steps[0][1].tsvd_.explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"The ParentTitleSparseTokenizer Explained Variance is {parent_title_explained_variance*100:0.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d76d1648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DirectorWriterSparseTokenizer initial dimension is 48686\n"
     ]
    }
   ],
   "source": [
    "director_writer_num_token = xgb_tokenizer_search.best_estimator_.steps[1][1].tokenized_matrix_.shape[0]\n",
    "\n",
    "print(f\"The DirectorWriterSparseTokenizer initial dimension is {director_writer_num_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7f64050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DirectorWriterSparseTokenizer Explained Variance is 2.0 %\n"
     ]
    }
   ],
   "source": [
    "director_writer_explained_variance = xgb_tokenizer_search.best_estimator_.steps[1][1].tsvd_.explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"The DirectorWriterSparseTokenizer Explained Variance is {director_writer_explained_variance*100:0.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f604d2",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e35f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance():\n",
    "    '''\n",
    "    This function extract the feature importance from the xgb_tokenizer_search object and return it \n",
    "    in a DataFrame\n",
    "    '''\n",
    "    feature_importance_col_list = selected_features_rfe.copy()\n",
    "\n",
    "    for col in range(125):\n",
    "        feature_importance_col_list.append('parentTconst_tsvd_' + str(col))\n",
    "    \n",
    "    for col in range(75):\n",
    "        feature_importance_col_list.append('director_writer_tsvd_' + str(col))\n",
    "        \n",
    "    feature_importance_df = pd.DataFrame(xgb_tokenizer_search.best_estimator_.steps[3][1].feature_importances_,\n",
    "                                         index = feature_importance_col_list, \n",
    "                                         columns = ['feature_importance']\n",
    "                                        )\n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9bfd4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "591e97e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Top 10 Features with the Highest Feature Importance Score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>parentTconst_tsvd_26</th>\n",
       "      <td>0.185252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentTconst_tsvd_84</th>\n",
       "      <td>0.061959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_movie</th>\n",
       "      <td>0.054445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Documentary</th>\n",
       "      <td>0.044295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Horror</th>\n",
       "      <td>0.024853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentTconst_tsvd_34</th>\n",
       "      <td>0.017664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_show_past_rating</th>\n",
       "      <td>0.017089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Drama</th>\n",
       "      <td>0.014170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentTconst_tsvd_12</th>\n",
       "      <td>0.009365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Reality-TV</th>\n",
       "      <td>0.008998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature_importance\n",
       "parentTconst_tsvd_26                0.185252\n",
       "parentTconst_tsvd_84                0.061959\n",
       "type_movie                          0.054445\n",
       "genre_Documentary                   0.044295\n",
       "genre_Horror                        0.024853\n",
       "parentTconst_tsvd_34                0.017664\n",
       "average_show_past_rating            0.017089\n",
       "genre_Drama                         0.014170\n",
       "parentTconst_tsvd_12                0.009365\n",
       "genre_Reality-TV                    0.008998"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The Top 10 Features with the Highest Feature Importance Score\")\n",
    "feature_importance_df.sort_values(by='feature_importance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "beba8dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bottom 10 Features with the Lowest Feature Importance Score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>type_tvEpisode</th>\n",
       "      <td>0.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentTconst_tsvd_5</th>\n",
       "      <td>0.001317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentTconst_tsvd_9</th>\n",
       "      <td>0.001399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentTconst_tsvd_45</th>\n",
       "      <td>0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentTconst_tsvd_13</th>\n",
       "      <td>0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentTconst_tsvd_2</th>\n",
       "      <td>0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_writer_tsvd_22</th>\n",
       "      <td>0.001602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_writer_tsvd_62</th>\n",
       "      <td>0.001606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentTconst_tsvd_38</th>\n",
       "      <td>0.001617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_writer_tsvd_13</th>\n",
       "      <td>0.001621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         feature_importance\n",
       "type_tvEpisode                     0.001136\n",
       "parentTconst_tsvd_5                0.001317\n",
       "parentTconst_tsvd_9                0.001399\n",
       "parentTconst_tsvd_45               0.001450\n",
       "parentTconst_tsvd_13               0.001482\n",
       "parentTconst_tsvd_2                0.001505\n",
       "director_writer_tsvd_22            0.001602\n",
       "director_writer_tsvd_62            0.001606\n",
       "parentTconst_tsvd_38               0.001617\n",
       "director_writer_tsvd_13            0.001621"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The Bottom 10 Features with the Lowest Feature Importance Score\")\n",
    "feature_importance_df.sort_values(by='feature_importance', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89218c37",
   "metadata": {},
   "source": [
    "## Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ec12ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permutation_importance():\n",
    "    '''\n",
    "    This function calculates the permutation importance of the xgb_tokenizer_search object and return it \n",
    "    in a DataFrame\n",
    "    '''\n",
    "    t0 = time.time()\n",
    "    print(\"Fitting started...\")\n",
    "    permutation_test = permutation_importance(xgb_tokenizer_search, X_test[selected_features], y_test, \n",
    "                                              n_repeats=5,random_state=0)\n",
    "    print(f\"Fitting took {time.time() - t0:0.3f}s.\")\n",
    "    \n",
    "    permutation_test_df = pd.DataFrame(permutation_test['importances_mean'],\n",
    "                                       index = X_train[selected_features].columns,\n",
    "                                       columns = ['permutation_importance_score']\n",
    "                                       )\n",
    "    \n",
    "    return permutation_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e05a6973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting started...\n",
      "Fitting took 119.957s.\n"
     ]
    }
   ],
   "source": [
    "permutation_test_df = get_permutation_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7eac192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Top 10 Features with the Highest Permutation Importance Score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permutation_importance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>parentTconst</th>\n",
       "      <td>0.362854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_show_past_rating</th>\n",
       "      <td>0.144627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numVotes</th>\n",
       "      <td>0.055699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>startYear</th>\n",
       "      <td>0.048718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_movie</th>\n",
       "      <td>0.045015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Documentary</th>\n",
       "      <td>0.039149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>directors_writers</th>\n",
       "      <td>0.038809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <td>0.036136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_median_past_rating</th>\n",
       "      <td>0.022302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_past_episode</th>\n",
       "      <td>0.021833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             permutation_importance_score\n",
       "parentTconst                                     0.362854\n",
       "average_show_past_rating                         0.144627\n",
       "numVotes                                         0.055699\n",
       "startYear                                        0.048718\n",
       "type_movie                                       0.045015\n",
       "genre_Documentary                                0.039149\n",
       "directors_writers                                0.038809\n",
       "runtimeMinutes                                   0.036136\n",
       "director_median_past_rating                      0.022302\n",
       "number_past_episode                              0.021833"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The Top 10 Features with the Highest Permutation Importance Score\")\n",
    "permutation_test_df.sort_values(by = 'permutation_importance_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4cb04d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bottom 10 Features with the Lowest Permutation Importance Score\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permutation_importance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>type_short</th>\n",
       "      <td>-0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_tvEpisode</th>\n",
       "      <td>-0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Game-Show</th>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_tvSpecial</th>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_no_genre</th>\n",
       "      <td>0.000475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_tvMiniSeries</th>\n",
       "      <td>0.000646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_History</th>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Sport</th>\n",
       "      <td>0.000737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Adventure</th>\n",
       "      <td>0.001510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_videoGame</th>\n",
       "      <td>0.001980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   permutation_importance_score\n",
       "type_short                            -0.000126\n",
       "type_tvEpisode                        -0.000006\n",
       "genre_Game-Show                        0.000247\n",
       "type_tvSpecial                         0.000468\n",
       "genre_no_genre                         0.000475\n",
       "type_tvMiniSeries                      0.000646\n",
       "genre_History                          0.000667\n",
       "genre_Sport                            0.000737\n",
       "genre_Adventure                        0.001510\n",
       "type_videoGame                         0.001980"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The Bottom 10 Features with the Lowest Permutation Importance Score\")\n",
    "permutation_test_df.sort_values(by = 'permutation_importance_score', ascending=True).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
